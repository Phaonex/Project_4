{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import seaborn as sn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Task 1 : Data Collection\n",
    "**importing data sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/latest_v3/.cereals.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-afeeb176b1bc>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mdata_crops\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'../data/latest_v3/.cereals.csv'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mdata_vegetables_2014\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'../data/latest_v3/veg_prod_2014.csv'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mdata_vegetables_2017\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'../data/latest_v3/veg_prod_2017.csv'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mdata_animals\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'../data/latest_v3/animal_products.csv'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mdata_population\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'../data/latest_v3/total_population.csv'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001B[0m\n\u001B[1;32m    684\u001B[0m     )\n\u001B[1;32m    685\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 686\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    687\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    688\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    450\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    451\u001B[0m     \u001B[0;31m# Create the parser.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 452\u001B[0;31m     \u001B[0mparser\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfp_or_buf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    453\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    454\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m    944\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    945\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 946\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    947\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    948\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[0;34m(self, engine)\u001B[0m\n\u001B[1;32m   1176\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_make_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mengine\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"c\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1177\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mengine\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"c\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1178\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mCParserWrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1179\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1180\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mengine\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"python\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, src, **kwds)\u001B[0m\n\u001B[1;32m   2006\u001B[0m         \u001B[0mkwds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"usecols\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0musecols\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2007\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2008\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reader\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mparsers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTextReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2009\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munnamed_cols\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reader\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munnamed_cols\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2010\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader.__cinit__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../data/latest_v3/.cereals.csv'"
     ]
    }
   ],
   "source": [
    "data_crops = pd.read_csv('../data/latest_v3/.cereals.csv')\n",
    "data_vegetables_2014 = pd.read_csv('../data/latest_v3/veg_prod_2014.csv')\n",
    "data_vegetables_2017 = pd.read_csv('../data/latest_v3/veg_prod_2017.csv')\n",
    "data_animals = pd.read_csv('../data/latest_v3/animal_products.csv')\n",
    "data_population = pd.read_csv('../data/latest_v3/total_population.csv')\n",
    "data_undernourished = pd.read_csv('../data/latest_v3/people_undernourished.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_crops.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_crops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_crops.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print( 'Crops has only one element:', data_crops.Element.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('All items:', data_crops.Item.unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of items:', len(data_crops.Item.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Area or country aggregate World + Total:', data_crops.Area.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Years:', data_crops.Year.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_vegetables_2017.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_vegetables_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_vegetables_2017.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print( 'Vegetable elements:', data_vegetables_2017.Element.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of elements:', len(data_vegetables_2017.Element.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('All items:', data_vegetables_2017.Item.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of items:', len(data_vegetables_2017.Item.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Area or countries:', data_vegetables_2017.Area.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Area or countries amount to:', len(data_vegetables_2017.Area.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Years:', data_vegetables_2017.Year.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_animals.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_animals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "data_animals.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print( 'Animal elements:', data_animals.Element.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of elements:', len(data_animals.Element.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('All items:', data_animals.Item.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Area or countries:', data_vegetables_2017.Area.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Area or countries amount to:', len(data_vegetables_2017.Area.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Years:', data_vegetables_2017.Year.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_population.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_population.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_population.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print( 'Population elements:', data_population.Element.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of elements:', len(data_population.Element.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('All items:', data_population.Item.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Area or countries:', data_population.Area.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Area or countries amount to:', len(data_population.Area.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Years:', data_population.Year.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_undernourished.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_undernourished.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print( 'Population elements:', data_undernourished.Element.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of elements:', len(data_undernourished.Element.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Area or countries:', data_undernourished.Area.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Area or countries amount to:', len(data_undernourished.Area.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Years:', data_undernourished.Year.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Replace NaN with zeros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_crops.fillna(0, inplace=True)\n",
    "data_undernourished.fillna(0, inplace=True)\n",
    "data_animals.fillna(0, inplace=True)\n",
    "data_vegetables_2017.fillna(0, inplace=True)\n",
    "data_population.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Converting value object dtype to a numerical one.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_undernourished.Value = pd.to_numeric(data_undernourished.Value, errors ='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**renaming data columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Task 2 : Data Discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Data default generated ids have been identified here:**\n",
    "\n",
    "They are simply all data set columns with \"code\" as its suffix like, Item Code, Area Code and Element Code etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creating properties Product origin that contain vegetal and animal\n",
    "data_vegetables =  data_vegetables_2014.append(data_vegetables_2017)\n",
    "data_animals['origin'] = 'animal'\n",
    "data_vegetables['origin'] = 'vegetal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a temporary dataframe combined from vegetables and animals products and rename its column name.\n",
    "temp = data_animals.append(data_vegetables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Columns selection according to Paul protocol.\n",
    "temp.columns = [\"xx\", \"xx2\", \"country_code\", \"country\", 'xx3', 'element'\n",
    ",'item_code', 'item', 'xx4', \"year\", \"unit\", \"value\", 'xx5', 'xx6'\n",
    ", 'origin']\n",
    "\n",
    "# Creating the main dataFrame pivot table that will be used to Answer most question.\n",
    "data = temp.pivot_table(\n",
    "index=[\"country_code\", \"country\", \"item_code\", \"item\", \"year\", \"origin\"],\n",
    "columns = [\"element\"], values=[\"value\"], aggfunc=sum)\n",
    "\n",
    "#elements_columns = pd.Series(data.columns.unique()).replace(regex={' ': '_', '[()]': '', '/': '_', '-': '_'}).str.lower()\n",
    "\n",
    "# Selecting columns based on elements.\n",
    "data.columns =  ['domestic_supply_quantity', 'export_quantity', 'fat_supply_quantity_g_capita_day', 'feed',\n",
    "'food', 'food_supply_kcal_capita_day',\n",
    "'food_supply_quantity_kg_capita_yr', 'import_quantity', 'losses', 'other_uses_non_food',\n",
    "'processing', 'production', 'protein_supply_quantity_g_capita_day',\n",
    "'residuals', 'seed', 'stock_variation', 'tourist_consumption']\n",
    "\n",
    "# removing not need columns like fat_supply_quantity_g_capita_day, residuals and tourist_consumption.\n",
    "data = data[ ['domestic_supply_quantity', 'export_quantity', 'feed',\n",
    "'food', 'food_supply_kcal_capita_day',\n",
    "'food_supply_quantity_kg_capita_yr', 'import_quantity', 'losses', 'other_uses_non_food',\n",
    "'processing', 'production', 'protein_supply_quantity_g_capita_day', 'seed', 'stock_variation',]]\n",
    "\n",
    "#Removing NaN values.\n",
    "#data.fillna(0, inplace=True)\n",
    "\n",
    "#data.drop(columns=['residuals', 'tourist_consumption', 'fat_supply_quantity_g_capita_day'], inplace= True)\n",
    "\n",
    "# Reset the index based on the pivot table and columns changes.\n",
    "data = data.reset_index()\n",
    "data = data[data.country_code != 351]\n",
    "\n",
    "\n",
    "col_renamed = {'Domain Code' : 'domain_code','Domain' : 'domain', 'Area Code' : 'country_code',\n",
    "                           'Area' : 'country', 'Element Code' : 'element_code','Element' : 'element',\n",
    "                           'Item Code' : 'item_code', 'Item' : 'item', 'Year Code' : 'year_code', 'Year' : 'year',\n",
    "                           'Unit' : 'unit', 'Value' : 'value', 'Flag' : 'flag', 'Flag Description' : 'flag_description'}\n",
    "\n",
    "data_crops =  data_crops.rename(columns= col_renamed)\n",
    "data_vegetables_2017 = data_vegetables_2017.rename(columns= col_renamed)\n",
    "data_animals = data_animals.rename(columns= col_renamed)\n",
    "data_population = data_population.rename(columns= col_renamed)\n",
    "data_undernourished = data_undernourished.rename(columns= col_renamed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Data vegetables and animals Summary statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Domestic supply quantity data redundancy equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_france = data_vegetables_2017[(data_vegetables_2017.country == 'France') & (data_vegetables_2017.item == 'Wheat and products')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_france.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "  **Calculating the 4 term equation of a specific country in this case france item Wheat and products, proving so some data redundancy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_france[data_france.loc[:]['element'] == 'Production'].value.values + \\\n",
    "data_france[data_france.loc[:]['element'] == 'Import Quantity'].value.values \\\n",
    "- data_france[data_france.loc[:]['element'] == 'Export Quantity'].value.values - \\\n",
    "data_france[data_france.loc[:]['element'] == 'Stock Variation'].value.values \\\n",
    "== data_france[data_france.loc[:]['element'] == 'Domestic supply quantity'].value.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This equation return to be **TRUE** Domestic supply quantity is a result of a 4 term equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 3 : Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Checking for data anomaly and removing it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## total world population\n",
    "\n",
    "calculating and find anomaly, removing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Using the above selection as mask for filtering the founded anomaly\n",
    "china =  data_population.loc[data_population.country_code == 351]\n",
    "# in FAO new methodology data set is this anomaly not present.\n",
    "china"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Creating World population constant**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Complete removing the already know data anomaly involved china and main land china.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_population.drop([60,61], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 7 631.1 this value is calculated according to FAO http://faostat.fao.org/static/syb/syb_5000.pdf\n",
    "WORLD_POPULATION = pd.DataFrame(data_population.groupby('year').value.sum() * 1000)\n",
    "WORLD_POPULATION.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 4 : Computing new variables\n",
    "**food_supply_kcal, food_supply_kgprotein, food_supply_kg, ratio_kcalkg, protein_percentage, dom_sup_kcal, dom_sup_kgprot**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To carry out your future study, you’ll need to compute new variables from the one you already have.\n",
    "\n",
    "Here is the list of variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- **_food_supply_kcal_ and _food_supply_kgprotein_**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a lite version of our population_df dataframe\n",
    "pop_data = data_population[['country_code', 'country', 'year', 'value']]\n",
    "pop_data['value'] = pop_data.value * 1000\n",
    "# Merging the population dataframe with the global food balance sheet dataframe\n",
    "data = pd.merge(data, pop_data, on=['country_code', 'country', 'year'] )\n",
    "# Renaming its column value to population to be more clear.\n",
    "data = data.rename(columns={'value': 'population'})\n",
    "\n",
    "# Calculating all need variables.\n",
    "data['food_supply_kcal'] = data.food_supply_kcal_capita_day * 365 * data.population\n",
    "data['food_supply_kgprotein'] = (data['protein_supply_quantity_g_capita_day'] * data['population'] * 365) / 1000\n",
    "data['food_supply_kg'] = data.food * np.power(10,6)\n",
    "data[['country_code','country','item_code','item','year','origin', 'food_supply_kcal', 'food_supply_kgprotein']].sample()\n",
    "# Creating Mask for preventing unsafe division by zero.\n",
    "mask = data.food_supply_kg != 0\n",
    "\n",
    "# Continue the calculation of the last 4 variables.\n",
    "data.loc[mask, 'ratio_kcalkg'] = data.loc[mask, \"food_supply_kcal\"] / data.loc[mask, \"food_supply_kg\"]\n",
    "data.loc[mask, 'protein_percentage'] = 100 * data.loc[mask, \"food_supply_kgprotein\"] / data.loc[mask, \"food_supply_kg\"]\n",
    "\n",
    "#creating the domestic variables\n",
    "data['dom_sup_kcal'] = data.domestic_supply_quantity * np.power(10,6) * data.ratio_kcalkg\n",
    "data['dom_sup_kgprot'] = (data.domestic_supply_quantity * np.power(10,6) * data.protein_percentage) / 100\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Generating great_import_from_undern_countries variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a new Dataframe copy by value so that original will not modified.\n",
    "people_undernourished_df = data_undernourished\n",
    "\n",
    "# Repassing undernourished based on a specific year range in this case 2014 to 2017.\n",
    "dictionary_year = {'2012-2014': 2013, '2013-2015':2014, '2014-2016': 2015, '2015-2017':2016, '2016-2018': 2017}\n",
    "people_undernourished_df['year'] = people_undernourished_df['year'].map(dictionary_year)\n",
    "\n",
    "# Creating another dataframe, this time keeping only the 'Area Code', 'Area', 'Year', 'Value' columns\n",
    "undernourished_data = people_undernourished_df[['country_code', 'country', 'year', 'value']]\n",
    "\n",
    "# Renaming its value for clarity.\n",
    "undernourished_data = undernourished_data.rename(columns={'value': 'u_population'})\n",
    "# Selecting specifics year range from 2014 to 2017\n",
    "undernourished_data = undernourished_data[(undernourished_data.year != 2013) & (undernourished_data.year != 2015) & (undernourished_data.year != 2016)]\n",
    "\n",
    "undernourished_data['u_population'] = pd.to_numeric(undernourished_data.u_population, errors ='coerce')\n",
    "# Recalculating values based on its unit.\n",
    "undernourished_data['u_population'] *= 1000000\n",
    "undernourished_data = undernourished_data[undernourished_data.country_code != 351]\n",
    "#Creating pop_data with only need columns\n",
    "pop_data = data_population[['country_code', 'country', 'year', 'value']]\n",
    "pop_data.columns = ['country_code', 'country', 'year', 'population']\n",
    "\n",
    "# reformatting values according to its unit.\n",
    "pop_data['population'] = pop_data.population * 1000\n",
    "pop_data = pop_data[pop_data.country_code != 351]\n",
    "\n",
    "# Merging it with population based on country code sort that for every county has its population and its undernourished value.\n",
    "pop_data = pd.merge(undernourished_data, pop_data, on=['country_code', 'country', 'year'] )\n",
    "mask = pop_data[\"population\"] != 0 # because it's not possible to divide by 0\n",
    "\n",
    "# Calculating undernourished in percentage.\n",
    "pop_data.loc[mask, 'u_percentage'] = 100 * pop_data.loc[mask, \"u_population\"] / pop_data.loc[mask, \"population\"]\n",
    "pop_data = pop_data[['country_code', 'country', 'year', 'population', 'u_population','u_percentage']]\n",
    "pop_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a merged dataframe containing the initial global food balance sheet data,\n",
    "# including the extra 7 columns created during Task 4 so far\n",
    "data = pd.merge(data, pop_data, on=['country_code', 'country', 'year'] )\n",
    "data = data.rename(columns={'population_y':'population'})\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Generating top 25 exports based on the undernourished percentage variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Creating the 25 most exported products.\n",
    "most_exported_products = data[data.u_percentage >=10]\n",
    "#Saving the top 25 sum grouped by our selected year 2014 and 2017.\n",
    "most_exported_products_2014 = most_exported_products[most_exported_products.year == 2014].groupby([ 'year','item_code','item'], as_index = False)[['export_quantity']].sum().sort_values(by=['export_quantity'], ascending=False).head(25)\n",
    "most_exported_products_2017 = most_exported_products[most_exported_products.year == 2017].groupby([ 'year','item_code','item'], as_index = False)[['export_quantity']].sum().sort_values(by=['export_quantity'], ascending=False).head(25)\n",
    "\n",
    "#Create the top 25 selected year data frame and updating its index.\n",
    "most_exported_products = pd.concat([most_exported_products_2014, most_exported_products_2017])\n",
    "most_exported_products = most_exported_products.reset_index(drop = True)\n",
    "\n",
    "#example for 2014\n",
    "most_exported_products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#example for 2017\n",
    "most_exported_products.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Generating top 200 imports based on the top 25 most exported products items**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Saving our most exported items based on most exported products items years from 2014 and 2017.\n",
    "most_exported_items_2014 = list(most_exported_products_2014['item'])\n",
    "most_exported_items_2017 = list(most_exported_products_2017['item'])\n",
    "\n",
    "# Creating the top 200 from 2014.\n",
    "most_imported_200_items_2014 = data[data.year==2014]\n",
    "most_imported_200_items_2014 = most_imported_200_items_2014[most_imported_200_items_2014.item.isin(most_exported_items_2014)] \\\n",
    ".groupby(['country', 'item', 'year'], as_index = False)[['import_quantity']].sum().sort_values(by=['import_quantity'], ascending=False).head(200)\n",
    "\n",
    "# Creating the top 200 from 2017.\n",
    "most_imported_200_items_2017 = data[data.year==2017]\n",
    "most_imported_200_items_2017 = most_imported_200_items_2017[most_imported_200_items_2017.item.isin(most_exported_items_2017)] \\\n",
    ".groupby(['country', 'item', 'year'], as_index = False)[['import_quantity']].sum().sort_values(by=['import_quantity'], ascending=False).head(200)\n",
    "\n",
    "#Creating the most imported 200 items with the selected years.\n",
    "most_imported_200_items = pd.concat([most_imported_200_items_2014, most_imported_200_items_2017])\n",
    "most_imported_200_items = most_imported_200_items.reset_index(drop = True)\n",
    "\n",
    "# From the most imported 200 items i create the great_import_from_undern_countries flag or mask to be used for\n",
    "# further calculation.\n",
    "most_imported_200_items['great_import_from_undern_countries'] = True\n",
    "\n",
    "#example for 2014\n",
    "most_imported_200_items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#example for 2017\n",
    "most_imported_200_items.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save most imported 200 items to our main data frame.\n",
    "data = pd.merge(data, most_imported_200_items, on=['country','item','year','import_quantity'], how='left' )\n",
    "# selecting macking sure that our data great_import_from_undern_countries that are NaN are boolean false.\n",
    "data[\"great_import_from_undern_countries\"] = data[\"great_import_from_undern_countries\"].fillna(False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Task 5 : Identify major trends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Assign vegetal oring values only to vegetables_data to be used on question that require only vegetables\n",
    "vegetables_data = data[:][data.origin == 'vegetal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**1. Considering only plant products, what proportion of the global domestic supply is used as :**\n",
    "    * food\n",
    "    * feed\n",
    "    * losses\n",
    "    * other uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Calculating the total global of all origin vegetables.\n",
    "used_plants_supply = data[data.origin == 'vegetal'].groupby(['year'], as_index = False)[['food', 'feed', 'losses', 'other_uses_non_food']].sum()\n",
    "\n",
    "# Caculating the domestic supply total.\n",
    "domestic_supply_quantity_total = data[data.origin == 'vegetal'].groupby(['year'], as_index = False).domestic_supply_quantity.sum()\n",
    "\n",
    "# Dividing the values in our used_plants_supply list by the 'domestic_supply_quantity' column value to get our list of proportions\n",
    "used_plants_supply['domestic_supply_quantity'] = domestic_supply_quantity_total.domestic_supply_quantity\n",
    "used_plants_supply=  pd.melt(used_plants_supply, id_vars=['year', 'domestic_supply_quantity'])\n",
    "\n",
    "# divide food, feed, losses, other_uses_non-food by domestic_supply_quantity to get ist global supply proportions.\n",
    "# divide by domestic surpply.\n",
    "used_plants_supply['proportion'] = (100*used_plants_supply['value'] / used_plants_supply.domestic_supply_quantity).round(2)\n",
    "used_plants_supply = used_plants_supply[['year','variable', 'proportion']]\n",
    "used_plants_supply = used_plants_supply.groupby(['year', 'variable']).sum()\n",
    "\n",
    "# Results\n",
    "used_plants_supply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**2. How many humans on earth could be fed if all the plant-based food supply (crops),\n",
    "including food and feed, was used for human consumption? Give the results in terms of calories, and protein.\n",
    "Express these two results as a percentage of the world's population.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Daily kcal, protein recommend Per capita and global average weight\n",
    "# according to Wikipedia https://en.wikipedia.org/wiki/Human_body_weight.\n",
    "NB_KCAL_PER_CAPITA_PER_DAY = 2500\n",
    "KG_PROT_PER_CAPITA_PER_DAY = 62 * 0.008\n",
    "\n",
    "# Creating our dataframe, by filtering the big dataframe (data) by the \"origin == 'vegetal'\" condition\n",
    "# while keeping only a handful of columns\n",
    "plants_human_consumption = data[data.origin == 'vegetal']\n",
    "plants_human_consumption = plants_human_consumption[['country','year', 'item_code', 'item', 'feed', 'food', 'ratio_kcalkg', 'protein_percentage']]\n",
    "\n",
    "# Calculating food_feed_kcal using it unit 10^6 extracting its kcal value from ration kcal kg.\n",
    "# Calculating food_feed_kgprot using it unit 10^6 extracting its kg value from protein percentage removing its percentage  0.1.\n",
    "plants_human_consumption['food_feed_kcal'] = (plants_human_consumption.feed + plants_human_consumption.food) * np.power(10,6) * plants_human_consumption.ratio_kcalkg\n",
    "plants_human_consumption['food_feed_kg_protein'] = ( np.power(10,6) * (plants_human_consumption.feed + plants_human_consumption.food)) * plants_human_consumption.protein_percentage / 100\n",
    "\n",
    "# Removing anomaly NaN.\n",
    "plants_human_consumption[\"food_feed_kcal\"] = plants_human_consumption.food_feed_kcal.fillna(0)\n",
    "plants_human_consumption[\"food_feed_kg_protein\"] = plants_human_consumption.food_feed_kg_protein.fillna(0)\n",
    "\n",
    "# Calculating food_feed_kcal and food_feed_kg_protein sum by year.\n",
    "plants_human_consumption = plants_human_consumption.groupby(['year'], as_index = False)[['food_feed_kcal', 'food_feed_kg_protein']].sum()\n",
    "\n",
    "## Creating food feed quantities in oder calculating its humans nutrients recommend values.\n",
    "# Recommended food and feed per capita\n",
    "plants_human_consumption['human_feed_energy'] = plants_human_consumption.food_feed_kcal / NB_KCAL_PER_CAPITA_PER_DAY / 365\n",
    "plants_human_consumption['human_feed_energy'] = plants_human_consumption.human_feed_energy.round(0)\n",
    "\n",
    "plants_human_consumption['human_feed_proteins'] = plants_human_consumption.food_feed_kg_protein / KG_PROT_PER_CAPITA_PER_DAY / 365\n",
    "plants_human_consumption['human_feed_proteins'] = plants_human_consumption.human_feed_proteins.round(0)\n",
    "\n",
    "# Creating the population dataframe and calculating the total population for both 2014 and 2017\n",
    "tmp_total_pop = data_population\n",
    "tmp_total_pop = tmp_total_pop[tmp_total_pop['flag_description'] == 'Standardized data']\n",
    "tmp_total_pop = 1000 * tmp_total_pop.groupby(['year']).value.sum()\n",
    "\n",
    "# Preparing tor results.\n",
    "plants_human_consumption = pd.merge(plants_human_consumption, tmp_total_pop, left_on='year', right_on='year')\n",
    "plants_human_consumption = plants_human_consumption.rename(columns={\"value\": \"population\"})\n",
    "\n",
    "# Calculating the percentage of Engine and Protein need for the global population.\n",
    "plants_human_consumption['percentage_human_feed_energy'] = 100 * plants_human_consumption.human_feed_energy / plants_human_consumption.population\n",
    "plants_human_consumption['percentage_human_feed_proteins'] = 100 * plants_human_consumption.human_feed_proteins / plants_human_consumption.population\n",
    "\n",
    "# Results\n",
    "plants_human_consumption[['year','percentage_human_feed_energy', 'percentage_human_feed_proteins']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**3. How many humans could be fed with the global food supply? Give the results in terms of calories and protein.\n",
    "Express these two results as a percentage of the world's population.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creating our dataframe, this time keeping the big dataframe (data) as it is\n",
    "# while still keeping only a handful of columns\n",
    "total_human_feed= data\n",
    "total_human_feed = total_human_feed[['country','year', 'item_code', 'item', 'feed', 'food', 'ratio_kcalkg', 'protein_percentage']]\n",
    "\n",
    "# Creating the two new columns kcal and food_feed_kg_protein\n",
    "total_human_feed['food_feed_kcal'] = (total_human_feed.feed + total_human_feed.food) * np.power(10,6) * total_human_feed.ratio_kcalkg\n",
    "total_human_feed['food_feed_kg_protein'] = np.power(10,6) * (total_human_feed.feed + total_human_feed.food) * (total_human_feed.protein_percentage /100)\n",
    "\n",
    "# Replacing the NaN values with zeros.\n",
    "total_human_feed[\"food_feed_kcal\"] = total_human_feed.food_feed_kcal.fillna(0)\n",
    "total_human_feed[\"food_feed_kg_protein\"] = total_human_feed.food_feed_kg_protein.fillna(0)\n",
    "\n",
    "# Grouping by year and summing the two new columns\n",
    "total_human_feed = total_human_feed.groupby(['year'], as_index = False)[['food_feed_kcal', 'food_feed_kg_protein']].sum()\n",
    "\n",
    "# Creating new columns calculating the amount of people that could've been fed (in 2014 and 2017)\n",
    "# First, by the amount of kcal in the crops.\n",
    "total_human_feed['human_feed_energy'] = total_human_feed.food_feed_kcal / NB_KCAL_PER_CAPITA_PER_DAY / 365\n",
    "total_human_feed['human_feed_energy'] = total_human_feed.human_feed_energy.round(0)\n",
    "\n",
    "# Second, by the amount of protein in the crops\n",
    "total_human_feed['human_feed_proteins'] = total_human_feed.food_feed_kg_protein / KG_PROT_PER_CAPITA_PER_DAY / 365\n",
    "total_human_feed['human_feed_proteins'] = total_human_feed.human_feed_proteins.round(0)\n",
    "\n",
    "\n",
    "# Preparing the results.\n",
    "total_human_feed = pd.merge(total_human_feed, tmp_total_pop, left_on='year', right_on='year')\n",
    "total_human_feed = total_human_feed.rename(columns={\"value\": \"population\"})\n",
    "\n",
    "# Calculating the percentage of Engine and Protein need for the global population . use the population from pop\n",
    "total_human_feed['percentage_human_feed_energy'] = 100 * total_human_feed.human_feed_energy / total_human_feed.population\n",
    "total_human_feed['percentage_human_feed_proteins'] = 100 * total_human_feed.human_feed_proteins / total_human_feed.population\n",
    "\n",
    "# Results.\n",
    "total_human_feed[['year','percentage_human_feed_energy', 'percentage_human_feed_proteins']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**4. From the collected data on undernutrition, what proportion of the world's population is considered undernourished?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Calculating the sum of the population by year.\n",
    "undernourished_proportion = pop_data.groupby(['year'])[['population', 'u_population']].sum()\n",
    "\n",
    "# Calculating the undernourished_proportion for the range year from 2014 to 2017.\n",
    "undernourished_proportion = 100 * undernourished_proportion.u_population/undernourished_proportion.population\n",
    "\n",
    "# Preparing the results\n",
    "undernourished = pd.DataFrame({'proportion':undernourished_proportion}, [2014, 2017])\n",
    "# Results\n",
    "undernourished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**5. Considering the 25 items most exported by the countries with a high rate of undernutrition, which three of them:**\n",
    "    1 Have the greatest other_uses_non_food to domestic_supply_quantity ratio and what are they used for?\n",
    "    2 Have the greatest feed to (food+feed) ratio and what are they used for?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*1 Have the greatest feed to (food+feed) ratio and what are they used for?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create ratio nbsp 2014 based on the most exported items with the selected columns.\n",
    "ratio_nbsp_2014 = data[data.year == 2014]\n",
    "ratio_nbsp_2014 = ratio_nbsp_2014[ratio_nbsp_2014.item.isin(most_exported_items_2014)].groupby(['country', 'item', 'year'], as_index = False)[['other_uses_non_food', 'domestic_supply_quantity']].sum()\n",
    "\n",
    "#Mask safe division\n",
    "safe_div_mask = ratio_nbsp_2014.domestic_supply_quantity != 0\n",
    "\n",
    "# Calculating the proportion of the most exported items in the other uses non food, ratio nbsp 2014 related to domestic supply quantity.\n",
    "ratio_nbsp_2014.loc[safe_div_mask,'ratio'] = ratio_nbsp_2014.loc[safe_div_mask, 'other_uses_non_food'] / ratio_nbsp_2014.loc[safe_div_mask, 'domestic_supply_quantity']\n",
    "ratio_nbsp_2014.ratio = ratio_nbsp_2014.ratio.fillna(0)\n",
    "ratio_nbsp_2014 = ratio_nbsp_2014.sort_values(by = ['ratio'], ascending = False).head(3)\n",
    "\n",
    "# Create ratio nbsp 2017 based on the most exported items with the selected columns.\n",
    "ratio_nbsp_2017 = data[data.year == 2017]\n",
    "ratio_nbsp_2017 = ratio_nbsp_2017[ratio_nbsp_2017.item.isin(most_exported_items_2017)].groupby(['country', 'item', 'year'], as_index = False)[['other_uses_non_food', 'domestic_supply_quantity']].sum()\n",
    "\n",
    "#Mask safe division\n",
    "safe_div_mask = ratio_nbsp_2017.domestic_supply_quantity != 0\n",
    "\n",
    "# Calculating the proportion of the most exported items in the other uses non food, ratio nbsp 2017 related to domestic supply quantity.\n",
    "ratio_nbsp_2017.loc[safe_div_mask,'ratio'] = ratio_nbsp_2017.loc[safe_div_mask, 'other_uses_non_food'] / ratio_nbsp_2017.loc[safe_div_mask, 'domestic_supply_quantity']\n",
    "ratio_nbsp_2017.ratio = ratio_nbsp_2017.ratio.fillna(0)\n",
    "ratio_nbsp_2017 = ratio_nbsp_2017.sort_values(by = ['ratio'], ascending = False).head(3)\n",
    "\n",
    "# Preparing the results\n",
    "results = pd.concat([ratio_nbsp_2014, ratio_nbsp_2017]).reset_index(drop= True)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*2 Have the greatest feed to (food+feed) ratio and what are they used for?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create ratio feed food nbsp 2014 based on the most exported items with the selected columns.\n",
    "ratio_feed_food_nbsp_2014 = data[data.year == 2014]\n",
    "ratio_feed_food_nbsp_2014 = ratio_feed_food_nbsp_2014[ratio_feed_food_nbsp_2014.item.isin(most_exported_items_2014)].groupby(['country', 'item', 'year'], as_index = False)[['food', 'feed']].sum()\n",
    "\n",
    "#Mask safe division\n",
    "safe_div_mask = (ratio_feed_food_nbsp_2014.food + ratio_feed_food_nbsp_2014.feed) != 0\n",
    "\n",
    "# Calculating the proportion of the most exported items in the other uses non food, ratio feed food nbsp 2014 related to domestic supply quantity.\n",
    "ratio_feed_food_nbsp_2014.loc[safe_div_mask,'ratio'] = ratio_feed_food_nbsp_2014.loc[safe_div_mask, 'feed'] / (ratio_feed_food_nbsp_2014.loc[safe_div_mask, 'feed'] + ratio_feed_food_nbsp_2014.loc[safe_div_mask, 'food'])\n",
    "ratio_feed_food_nbsp_2014.ratio = ratio_feed_food_nbsp_2014.ratio.fillna(0)\n",
    "ratio_feed_food_nbsp_2014 = ratio_feed_food_nbsp_2014.sort_values(by = ['ratio'], ascending = False).head(3)\n",
    "\n",
    "ratio_feed_food_nbsp_2017 = data[data.year == 2017]\n",
    "ratio_feed_food_nbsp_2017 = ratio_feed_food_nbsp_2017[ratio_feed_food_nbsp_2017.item.isin(most_exported_items_2017)].groupby(['country', 'item', 'year'], as_index = False)[['food', 'feed']].sum()\n",
    "\n",
    "#Mask safe division\n",
    "safe_div_mask = (ratio_feed_food_nbsp_2017.food + ratio_feed_food_nbsp_2017.feed) != 0\n",
    "\n",
    "# Calculating the proportion of the most exported items in the other uses non food, ratio nbsp 2017 related to domestic supply quantity.\n",
    "ratio_feed_food_nbsp_2017.loc[safe_div_mask,'ratio'] = ratio_feed_food_nbsp_2017.loc[safe_div_mask, 'feed'] / (ratio_feed_food_nbsp_2017.loc[safe_div_mask, 'feed'] + ratio_feed_food_nbsp_2017.loc[safe_div_mask, 'food'])\n",
    "ratio_feed_food_nbsp_2017.ratio = ratio_feed_food_nbsp_2017.ratio.fillna(0)\n",
    "ratio_feed_food_nbsp_2017 = ratio_feed_food_nbsp_2017.sort_values(by = ['ratio'], ascending = False).head(3)\n",
    "\n",
    "# Concatenating the two dataframes\n",
    "results = pd.concat([ratio_feed_food_nbsp_2014, ratio_feed_food_nbsp_2017]).reset_index(drop=True)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**6. Taking only grains (cereals) for food and feed into account, what proportion (in terms of weight) is used for feed?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creating only cereal columns on the all food and animal data set.\n",
    "cereals_data = pd.read_csv(\"../data/latest_v3/cereals.csv\")\n",
    "cereals = cereals_data['Item'].unique()\n",
    "cereals\n",
    "\n",
    "#Selecting items and food and feed columns cereals only\n",
    "only_cereal = data[data['item'].isin(cereals)].groupby(['year'], as_index = False)[['food', 'feed']].sum()\n",
    "\n",
    "#Mask safe division\n",
    "safe_div_mask = (only_cereal[\"food\"]+ only_cereal[\"feed\"]) != 0\n",
    "\n",
    "# Preparing the results food and feed proportion ass percentage\n",
    "only_cereal.loc[safe_div_mask,'percentage'] = round(100*only_cereal.loc[safe_div_mask, 'feed']/(only_cereal.loc[safe_div_mask, 'food'] + only_cereal.loc[safe_div_mask, 'feed']))\n",
    "only_cereal[['year', 'percentage']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**7. How many tons of grains (cereals) could be released if the US reduced its production of animal products by 10%?\n",
    "Convert this quantity to kcal, and the number of potentially fed humans.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creating USA cereal only data set for the last year in this case 2017.\n",
    "USA_Cereals_data = data[data.item.isin(cereals)]\n",
    "USA_Cereals_data = USA_Cereals_data[USA_Cereals_data.country == 'United States of America']\n",
    "USA_Cereals_data = USA_Cereals_data[USA_Cereals_data.year == 2017]\n",
    "\n",
    "# Calculating the total USA cereals feed of 10% in kg.\n",
    "USA_Cereals_dataa = USA_Cereals_data.feed.sum()*1000*0.1\n",
    "\n",
    "# Calculating the total USA cereals feed of 10% in kcal.\n",
    "USA_Cereals_datab = round((USA_Cereals_data.feed*1000*0.1  * USA_Cereals_data.ratio_kcalkg).sum(), 0)\n",
    "\n",
    "# Calculating the total of feed Humans energy with the USA cereals only.\n",
    "USA_Cereals_datac = round(USA_Cereals_datab/NB_KCAL_PER_CAPITA_PER_DAY, 0)\n",
    "\n",
    "#Preparing the results.\n",
    "results = pd.DataFrame(np.array([[USA_Cereals_dataa, USA_Cereals_datab, USA_Cereals_datac]]), columns=['10%_feed_kg', '10%_feed_kcal', 'potential_humans_fed'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**8. In Thailand, what proportion of cassava is exported? What is the proportion of undernutrition?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creating Thailand vegetables data set.\n",
    "thai_vegetables_data = data[data.country == 'Thailand']\n",
    "\n",
    "# Filtering Cassava Products from Thailand vegetables.\n",
    "thai_vegetables_data = thai_vegetables_data[thai_vegetables_data.item == 'Cassava and products']\n",
    "\n",
    "# Selecting the need columns.\n",
    "thai_vegetables_data = thai_vegetables_data[['year','country','item','domestic_supply_quantity', 'export_quantity', 'feed', 'food', 'import_quantity', 'losses',\n",
    "         'other_uses_non_food', 'processing', 'production', 'seed', 'stock_variation', 'u_percentage']]\n",
    "\n",
    "# Calculating the proportion of Cassava production export.\n",
    "thai_vegetables_data['proportion_exported_quantity'] = 100*(thai_vegetables_data['feed'] + thai_vegetables_data['food'] + thai_vegetables_data['losses'] + thai_vegetables_data['other_uses_non_food'])/thai_vegetables_data['export_quantity']\n",
    "thai_vegetables_data[['year','country','item','proportion_exported_quantity', 'u_percentage']].set_index('year')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}