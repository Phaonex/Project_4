{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Primary keys for each table**\n",
    "- Total population:   _Area Code_ & _Year Code_\n",
    "- Animal products:    _Area Code_ & _Item Code_ & _Element_ & _Year Code_\n",
    "- Vegetal products:   _Area Code_ & _Item Code_ & _Element_ & _Year Code_\n",
    "- Cereals: _Item Code_\n",
    "- People undernourished: _Area Code_ & _Year Code_\n",
    "\n",
    "Or simply an auto-generated id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After checking the **\"Definition and standards\"** section on the FAO website, we realised some elements are redundant.\n",
    "\n",
    "We learned that:\n",
    "      \n",
    "      \n",
    "    Production + Import Quantity - Export Quantity - Stock Variation = Domestic supply quantity  =  \n",
    "    = Feed + Seed + Losses + Processing + Other uses (non-food) + Residuals + Food \n",
    "\n",
    "To illustrate this, we have taken the example of _Wheat and Products_ in France:\n",
    "\n",
    "\n",
    "    38950 + 2394  -(-1209) - 22226 = 20327 = 7524 + 770 + 359 + 1788 + 2851 + 0 + 7035 \n",
    "        \n",
    "We conclude that the _Domestic supply quantity_ column is redundant. (Obviously, there are also a few descriptive columns like _Domain Code_ , _Domain_ , _Flag_ that are also considered redundant to our study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File data/veg_prod_2014.csv does not exist: 'data/veg_prod_2014.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a796f13ca53b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwheat_france\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/veg_prod_2014.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwheat_france\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwheat_france\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwheat_france\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Area'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'France'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwheat_france\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Item'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Wheat and products'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwheat_france\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Area'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Element'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Item'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/untitled1/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/untitled1/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/untitled1/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/untitled1/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/untitled1/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File data/veg_prod_2014.csv does not exist: 'data/veg_prod_2014.csv'"
     ]
    }
   ],
   "source": [
    "wheat_france = pd.read_csv(\"data/veg_prod_2014.csv\")\n",
    "wheat_france = wheat_france[(wheat_france['Area']=='France') & (wheat_france['Item'] == 'Wheat and products')].reset_index()\n",
    "wheat_france[['Area', 'Element', 'Item', 'Value']][:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating our initial population dataframe\n",
    "population_data = pd.read_csv(\"data/total_population.csv\")\n",
    "population_df = pd.DataFrame(data = population_data)\n",
    "population_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the world population for 2014 and 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creating a dataframe of population that contains both 2014 and 2017 population data\n",
    "# Keeping only the entries that are of the form \"Standardized data\" so as to eliminate duplicate information\n",
    "# e.g. China has both 2 sets of entries: standardized (per regions) and aggregated\n",
    "pop_2014_and_2017 = population_df[population_df['Flag Description'] == 'Standardized data']\n",
    "\n",
    "# Grouping by year\n",
    "pop_2014_and_2017 = pop_2014_and_2017.groupby(['Year'])\n",
    "\n",
    "# Creating an array containing two elememnts, one for 2014 and one for 2017\n",
    "pop_2014_and_2017_array = np.array(pop_2014_and_2017)\n",
    "\n",
    "# Saving the sum over the population data for 2014 and 2017 respectively\n",
    "world_population_2014 = int(1000*pop_2014_and_2017_array[0][1][['Value']].sum())\n",
    "world_population_2017 = int(1000*pop_2014_and_2017_array[1][1][['Value']].sum())\n",
    "\n",
    "# Creating a list with two entries, each entry showing the year and the world population calculated for that year\n",
    "world_population = [[2014, world_population_2014], [2017,world_population_2017]]\n",
    "pd.DataFrame(np.array(world_population), columns = ['year', 'world_population'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#FAO Data - Cleaning - Paul\n",
    "# The goal is to format the main dataframe (food balance) to have a column for each element, e.g.\n",
    "# Production, Importation, Domestic supply, Seed, etc.,\n",
    "# This way, the data manipulation will be much easier!\n",
    "\n",
    "\n",
    "# Loads the food balance data\n",
    "veg1 = pd.read_csv(\"data/veg_prod_2014.csv\")\n",
    "veg2 = pd.read_csv(\"data/veg_prod_2017.csv\")\n",
    "ani = pd.read_csv(\"data/animal_products.csv\")\n",
    "veg = veg1.append(veg2)\n",
    "\n",
    "# Adds variable ‘origin’\n",
    "ani[\"origin\"] = \"animal\"\n",
    "veg[\"origin\"] = \"vegetal\"\n",
    "\n",
    "# Appends veg and ani to one dataframe\n",
    "temp = ani.append(veg)\n",
    "\n",
    "#Deletion of ani et veg\n",
    "del ani, veg\n",
    "\n",
    "#Renaming of temp’s columns\n",
    "temp.columns = [\"xx\", \"xx2\", \"country_code\", \"country\", 'xx3', 'element'\n",
    ",'item_code', 'item', 'xx4', \"year\", \"unit\", \"value\", 'xx5', 'xx6'\n",
    ", 'origin']\n",
    "\n",
    "# Transformation of ‘temp’ to a pivot table\n",
    "data = temp.pivot_table(\n",
    "index=[\"country_code\", \"country\", \"item_code\", \"item\", \"year\", \"origin\"],\n",
    "columns = [\"element\"], values=[\"value\"], aggfunc=sum)\n",
    "\n",
    "\n",
    "# Renaming of data’s columns (be careful, the order of the columns needs\n",
    "# to be adapted to your own data !)\n",
    "# Yes, I was, I had to add 'residuals', 'tourist_consumption' and 'fat_supply_quantity_gcapitaday'\n",
    "data.columns = ['domestic_supply_quantity', 'export_quantity', 'fat_supply_quantity_gcapitaday', 'feed',\n",
    "'food', 'food_supply_kcalcapitaday',\n",
    "'food_supply_quantity_kgcapitayr', 'import_quantity', 'losses', 'other_uses',\n",
    "'processing', 'production', 'protein_supply_quantity_gcapitaday',\n",
    "'residuals', 'seed', 'stock_variation', 'tourist_consumption']\n",
    "\n",
    "# Getting rid of the three extra columns post pivotation\n",
    "data = data[['domestic_supply_quantity', 'export_quantity', 'feed',\n",
    "'food', 'food_supply_kcalcapitaday',\n",
    "'food_supply_quantity_kgcapitayr', 'import_quantity', 'losses', 'other_uses',\n",
    "'processing', 'production', 'protein_supply_quantity_gcapitaday',\n",
    " 'seed', 'stock_variation']]\n",
    "\n",
    "\n",
    "#Index columns need to be normal columns\n",
    "data = data.reset_index()\n",
    "data = data[data.country_code != 351]\n",
    "data.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To carry out your future study, you’ll need to compute new variables from the one you already have.\n",
    "\n",
    "Here is the list of variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **_food_supply_kcal_ and _food_supply_kgprotein_**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a lite version of our population_df dataframe\n",
    "pop_data = population_df[['Area Code', 'Area', 'Year', 'Value']]\n",
    "pop_data['Value'] = pop_data['Value']*1000\n",
    "pop_data.columns = ['country_code', 'country', 'year', 'population']\n",
    "\n",
    "# Merging the population dataframe with the global food balance sheet dataframe\n",
    "data1 = pd.merge(data, pop_data, on=['country_code', 'country', 'year'] )\n",
    "\n",
    "# Creating the food_supply_kcal and food_supply_kgprotein columns\n",
    "data1['food_supply_kcal'] = data1['food_supply_kcalcapitaday']*365*data1['population']\n",
    "data1['food_supply_kgprotein'] = (data1['protein_supply_quantity_gcapitaday']*data1['population']*365)/1000\n",
    "\n",
    "data1[['country_code','country','item_code','item','year','origin', 'food_supply_kcal', 'food_supply_kgprotein']].sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **_food_supply_kg_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating the food_supply_kg column\n",
    "data1['food_supply_kg'] = data1['food']*(10**6)\n",
    "\n",
    "data1[['country_code','country','item_code','item','year','origin', 'food_supply_kg']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **_ratio_kcalkg_ and _protein_percentage_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating the ratio_kcalkg and protein_percentage columns\n",
    "# We need a mask in order to avoid division by 0\n",
    "mask = data1[\"food_supply_kg\"] != 0 \n",
    "data1.loc[mask, 'ratio_kcalkg'] = data1.loc[mask, \"food_supply_kcal\"] / data1.loc[mask, \"food_supply_kg\"]\n",
    "data1.loc[mask, 'protein_percentage'] = 100*data1.loc[mask, \"food_supply_kgprotein\"] / data1.loc[mask, \"food_supply_kg\"]\n",
    "\n",
    "data1[['country_code','country','item_code','item','year','origin', 'ratio_kcalkg', 'protein_percentage']].sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **_dom_sup_kcal_ and _dom_sup_kgprot_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creating the dom_sup_kcal and dom_sup_kgprot columns\n",
    "data1['dom_sup_kcal'] = data1['domestic_supply_quantity']*(10**6)*data1['ratio_kcalkg']\n",
    "data1['dom_sup_kgprot'] = (data1['domestic_supply_quantity']*(10**6)*data1['protein_percentage'])/100\n",
    "\n",
    "data1[['country_code','country','item_code','item','year','origin', 'dom_sup_kcal', 'dom_sup_kcal']].sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **_great_import_from_undern_countries_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, I read the people_undernourished.csv file and create our people_undernourished_df dataframe\n",
    "people_undernourished_df = pd.read_csv(\"data/people_undernourished.csv\")\n",
    "\n",
    "# Formatting the year data, from 201(x-1) - 201(x+1) to 201x\n",
    "dictionary_year = {'2012-2014': 2013, '2013-2015':2014, '2014-2016': 2015, '2015-2017':2016, '2016-2018': 2017}\n",
    "people_undernourished_df['Year'] = people_undernourished_df['Year'].map(dictionary_year)\n",
    "\n",
    "# Creating another dataframe, this time keeping only the 'Area Code', 'Area', 'Year', 'Value' columns\n",
    "undernourished_data = people_undernourished_df[['Area Code', 'Area', 'Year', 'Value']]\n",
    "\n",
    "# Renaming the columns to the names mentioned in Task 3\n",
    "undernourished_data.columns = ['country_code', 'country', 'year', 'u_population']\n",
    "\n",
    "# Keeping only the data for 2014 and 2017\n",
    "undernourished_data = undernourished_data[(undernourished_data.year != 2013) & (undernourished_data.year != 2015) & (undernourished_data.year != 2016)]\n",
    "\n",
    "# Formatting the data for the 'u_population' column; \n",
    "# also, eliminating the rows coresponding to 'China' as they present aggregated data\n",
    "undernourished_data['u_population'] = pd.to_numeric(undernourished_data['u_population'], errors ='coerce')\n",
    "undernourished_data['u_population'] *= 1000000\n",
    "undernourished_data = undernourished_data[undernourished_data.country_code != 351]\n",
    "\n",
    "# Here we have a striped version of our initial population_df dataframe containing only the 'Area Code', 'Area', 'Year', 'Value' columns\n",
    "# Renaming the columns accordingly for these too\n",
    "# Formatting the 'population' column accordingly\n",
    "# Eliminating the rows for 'China' due to aggregated data\n",
    "pop_data = population_df[['Area Code', 'Area', 'Year', 'Value']]\n",
    "pop_data.columns = ['country_code', 'country', 'year', 'population']\n",
    "pop_data['population'] = pop_data['population']*1000\n",
    "pop_data = pop_data[pop_data.country_code != 351]\n",
    "\n",
    "# Merging the undernourished_data and the pop_data dataframes\n",
    "pop_data2 = pd.merge(undernourished_data, pop_data, on=['country_code', 'country', 'year'] )\n",
    "mask = pop_data2[\"population\"] != 0 # because it's not possible to divide by 0\n",
    "\n",
    "# Finally calculating the percentage of undernourished people for each country for our pop_data2 dataframe\n",
    "pop_data2.loc[mask, 'u_percentage'] = 100*pop_data2.loc[mask, \"u_population\"]/pop_data2.loc[mask, \"population\"]\n",
    "pop_data2 = pop_data2[['country_code', 'country', 'year', 'population', 'u_population','u_percentage']]\n",
    "pop_data2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creating a merged dataframe containing the initial global food balance sheet data, \n",
    "# including the extra 7 columns created during Task 4 so far\n",
    "data2 = pd.merge(data1, pop_data2, on=['country_code', 'country', 'year'] )\n",
    "data2 = data2.rename(columns={'population_y':'population'})\n",
    "\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - top 25 exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now, creating the two dataframes containing the 25 most exported items from countries with an undernourished perc. over 10%\n",
    "# for 2014, and 2017 respectively\n",
    "top_25_exports = data2[data2.u_percentage >=10]\n",
    "top_25_exports_2014 = top_25_exports[top_25_exports.year == 2014].groupby([ 'year','item_code','item'], as_index = False)[['export_quantity']].sum().sort_values(by=['export_quantity'], ascending=False).head(25)\n",
    "top_25_exports_2017 = top_25_exports[top_25_exports.year == 2017].groupby([ 'year','item_code','item'], as_index = False)[['export_quantity']].sum().sort_values(by=['export_quantity'], ascending=False).head(25)\n",
    "\n",
    "# Concatenating the above dataframes into a single one\n",
    "top_25_exports = pd.concat([top_25_exports_2014, top_25_exports_2017])\n",
    "top_25_exports = top_25_exports.reset_index(drop = True)\n",
    "\n",
    "top_25_exports.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - top 200 imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Then, here we have the lists with the 25 most exported items in 2014 and 2017, respectively\n",
    "most_exported_items_2014 = list(top_25_exports_2014['item'])\n",
    "most_exported_items_2017 = list(top_25_exports_2017['item'])\n",
    "\n",
    "# The dataframe containing the top 200 imports (of the 25 most exported items) in 2014\n",
    "top_200_imports_2014 = data2[data2.year==2014]\n",
    "top_200_imports_2014 = top_200_imports_2014[top_200_imports_2014.item.isin(most_exported_items_2014)].groupby(['country', 'item', 'year'], as_index = False)[['import_quantity']].sum().sort_values(by=['import_quantity'], ascending=False).head(200)\n",
    "\n",
    "# The dataframe containing the top 200 imports (of the 25 most exported items) in 2017\n",
    "top_200_imports_2017 = data2[data2.year==2017]\n",
    "top_200_imports_2017 = top_200_imports_2017[top_200_imports_2017.item.isin(most_exported_items_2017)].groupby(['country', 'item', 'year'], as_index = False)[['import_quantity']].sum().sort_values(by=['import_quantity'], ascending=False).head(200)\n",
    "\n",
    "# The concatenated dataframe of the top 200 imports of both 2014 and 2017\n",
    "# No. of rows = 400\n",
    "top_200_imports = pd.concat([top_200_imports_2014, top_200_imports_2017])\n",
    "top_200_imports = top_200_imports.reset_index(drop = True)\n",
    "\n",
    "# Creating the new column 'great_import_from_undern_countries' and setting the values for all entries to True\n",
    "top_200_imports['great_import_from_undern_countries'] = True\n",
    "\n",
    "top_200_imports.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally, our global food balance sheet data containing the extra 8 columns created during Task 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating our final dataframe containing all 32 columns (including the 8 new created during Task 4)\n",
    "# through a merging process between our data2 and top_200_imports dataframes\n",
    "data3 = pd.merge(data2, top_200_imports, on=['country','item','year','import_quantity'], how='left' )\n",
    "\n",
    "# Setting the NaN values to False (so we only have 400 values - 200 for each year)\n",
    "data3[\"great_import_from_undern_countries\"] = data3[\"great_import_from_undern_countries\"].fillna(False)\n",
    "data3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Considering only plant products, what proportion of the global domestic supply is used as food, feed, losses and other uses.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extracting a list with the sum values over the 'food', 'feed', 'losses', 'other_uses' columns\n",
    "q1a= data1[data1.origin=='vegetal'].groupby(['year'], as_index = False)[['food', 'feed', 'losses', 'other_uses']].sum()\n",
    "\n",
    "# Getting our float value of the 'domestic_supply_quantity' column\n",
    "q1b = data1[data1.origin=='vegetal'].groupby(['year'], as_index = False)[['domestic_supply_quantity']].sum()\n",
    "\n",
    "# Dividing the values in our q1a list by the 'domestic_supply_quantity' column value to get our list of proportions\n",
    "q1a['domestic_supply_quantity'] = q1b['domestic_supply_quantity']\n",
    "q1a=  pd.melt(q1a, id_vars=['year', 'domestic_supply_quantity'])\n",
    "q1a['proportion'] = (100*q1a['value']/ q1a['domestic_supply_quantity']).round(2)\n",
    "q1a = q1a[['year','variable', 'proportion']]\n",
    "q1a = q1a.groupby(['year', 'variable']).sum()\n",
    "q1a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. How many humans on earth could be fed if all the plant-based food supply (crops), including food and feed, was used for human consumption? Give the results in terms of calories, and protein. Express these two results as a percentage of the world's population.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our dataframe, by filtering the big dataframe (data2) by the \"origin == 'vegetal'\" condition\n",
    "# while keeping only a handful of columns\n",
    "q2a= data2[data2.origin=='vegetal']\n",
    "q2a = q2a[['country','year', 'item_code', 'item', 'feed', 'food', 'ratio_kcalkg', 'protein_percentage']]\n",
    "\n",
    "# Creating the two new columns kcal and food_feed_kg_protein\n",
    "q2a['kcal'] = (q2a['feed'] + q2a['food']) * 1000000* q2a['ratio_kcalkg']\n",
    "q2a['food_feed_kg_protein'] = (1000000*(q2a['feed'] + q2a['food'])) * q2a['protein_percentage']/100\n",
    "\n",
    "# Replacing the NaN values with zeros\n",
    "q2a[\"kcal\"] = q2a[\"kcal\"].fillna(0)\n",
    "q2a[\"food_feed_kg_protein\"] = q2a[\"food_feed_kg_protein\"].fillna(0)\n",
    "\n",
    "# Grouping by year and summing the two new columns\n",
    "q2a = q2a.groupby(['year'], as_index = False)[['kcal', 'food_feed_kg_protein']].sum()\n",
    "\n",
    "# Daily calorie and protein requirements for the average human\n",
    "daily_calorie_req = 2500 # [kcal]\n",
    "avg_body_weight = 62 # [kg]\n",
    "dri_protein = 0.008 # daily recommended intake; [g/kg] of body weight\n",
    "\n",
    "# Creating new columns calculating the amount of people that could've been fed (in 2014 and 2017)\n",
    "# First, by the amount of kcal in the crops\n",
    "# Second, by the amount of protein in the crops\n",
    "q2a['people_fed_bykcal']=q2a['kcal']/daily_calorie_req/365\n",
    "q2a['people_fed_bykcal'] = q2a['people_fed_bykcal'].round(0)\n",
    "\n",
    "q2a['people_fed_bykgprotein'] = q2a['food_feed_kg_protein']/(avg_body_weight*dri_protein)/365\n",
    "q2a['people_fed_bykgprotein'] = q2a['people_fed_bykgprotein'].round(0)\n",
    "\n",
    "# Creating the population dataframe and calculating the total population for both 2014 and 2017\n",
    "q2b = pd.read_csv(\"data/total_population.csv\")\n",
    "q2b = q2b[q2b['Flag Description'] == 'Standardized data']\n",
    "q2b = 1000*q2b.groupby(['Year'])[['Value']].sum()\n",
    "\n",
    "# Merging our two dataframes and finding our final values\n",
    "q2c = pd.merge(q2a, q2b, left_on='year', right_on='Year')\n",
    "q2c = q2c.rename(columns={\"Value\": \"Population\"})\n",
    "q2c['percentage_w_pop_fed_bykcal'] = 100*q2c['people_fed_bykcal']/q2c['Population']\n",
    "q2c['percentage_w_pop_fed_bykgprotein'] = 100*q2c['people_fed_bykgprotein']/q2c['Population']\n",
    "q2c[['year','percentage_w_pop_fed_bykcal', 'percentage_w_pop_fed_bykgprotein']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. How many humans could be fed with the global food supply? Give the results in terms of calories and protein. Express these two results as a percentage of the world's population.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating our dataframe, this time keeping the big dataframe (data2) as it is\n",
    "# while still keeping only a handful of columns\n",
    "q3a= data2\n",
    "q3a = q3a[['country','year', 'item_code', 'item', 'feed', 'food', 'ratio_kcalkg', 'protein_percentage']]\n",
    "\n",
    "# Creating the two new columns kcal and food_feed_kg_protein\n",
    "q3a['kcal'] = (q3a['feed'] + q3a['food']) * 1000000 * q3a['ratio_kcalkg']\n",
    "q3a['food_feed_kg_protein'] = 1000000*(q3a['feed'] + q3a['food']) * (q3a['protein_percentage']/100)\n",
    "\n",
    "# Replacing the NaN values with zeros\n",
    "q3a[\"kcal\"] = q3a[\"kcal\"].fillna(0)\n",
    "q3a[\"food_feed_kg_protein\"] = q3a[\"food_feed_kg_protein\"].fillna(0)\n",
    "\n",
    "# Grouping by year and summing the two new columns\n",
    "q3a = q3a.groupby(['year'], as_index = False)[['kcal', 'food_feed_kg_protein']].sum()\n",
    "\n",
    "# Daily calorie and protein requirements for the average human\n",
    "daily_calorie_req = 2500 # [kcal]\n",
    "avg_body_weight = 62 # [kg]\n",
    "dri_protein = 0.008 # daily recommended intake; [g/kg] of body weight\n",
    "\n",
    "# Creating new columns calculating the amount of people that could've been fed (in 2014 and 2017)\n",
    "# First, by the amount of kcal in the crops\n",
    "q3a['people_fed_bykcal']=q3a['kcal']/daily_calorie_req/365\n",
    "q3a['people_fed_bykcal'] = q3a['people_fed_bykcal'].round(0)\n",
    "\n",
    "# Second, by the amount of protein in the crops\n",
    "q3a['people_fed_bykgprotein'] = q3a['food_feed_kg_protein']/(avg_body_weight*dri_protein)/365\n",
    "q3a['people_fed_bykgprotein'] = q3a['people_fed_bykgprotein'].round(0)\n",
    "\n",
    "# Creating the population dataframe and calculating the total population for both 2014 and 2017\n",
    "q3b = pd.read_csv(\"data/total_population.csv\")\n",
    "q3b = q3b[q3b['Flag Description'] == 'Standardized data']\n",
    "q3b = 1000*q3b.groupby(['Year'])[['Value']].sum()\n",
    "\n",
    "# Merging our two dataframes and finding our final values\n",
    "q3c = pd.merge(q3a, q3b, left_on='year', right_on='Year')\n",
    "q3c = q3c.rename(columns={\"Value\": \"Population\"})\n",
    "q3c['percentage_w_pop_fed_bykcal'] = 100*q3c['people_fed_bykcal']/q3c['Population']\n",
    "\n",
    "q3c['percentage_w_pop_fed_bykgprotein'] = 100*q3c['people_fed_bykgprotein']/q3c['Population']\n",
    "\n",
    "q3c[['year','percentage_w_pop_fed_bykcal', 'percentage_w_pop_fed_bykgprotein']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. From the collected data on undernutrition, what proportion of the world's population is considered undernourished?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creating a dataframe from the previously created population dataframe, \n",
    "# keeping and summing only the 'population', 'u_population' columns\n",
    "# after grouping by 'year'\n",
    "q4a = pop_data2.groupby(['year'])[['population', 'u_population']].sum()\n",
    "\n",
    "# Creating a list of the two values of undernourished proportion in 2014 and 2017 respectively\n",
    "q4b = 100*q4a.u_population/q4a.population\n",
    "\n",
    "# Creating our mini-dataframe using our q4b list\n",
    "q4c= pd.DataFrame({'proportion':q4b}, [2014, 2017])\n",
    "\n",
    "q4c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Considering the 25 items most exported by the countries with a high rate of undernutrition, which three of them:**\n",
    "\n",
    "- Have the greatest _other_uses_ to _domestic_supply_quantity_ ratio and what are they used for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a dataframe that only includes the 25 most exported items in 2014, \n",
    "# while keeping only the 'country', 'item', 'year','other_uses', 'domestic_supply_quantity' columns\n",
    "q5a_2014 = data2[data2.year==2014]\n",
    "q5a_2014 = q5a_2014[q5a_2014.item.isin(most_exported_items_2014)].groupby(['country', 'item', 'year'], as_index = False)[['other_uses', 'domestic_supply_quantity']].sum()\n",
    "\n",
    "# Creating our 'other_uses' to 'domestic_supply_quantity' ratio column\n",
    "maskq5a = q5a_2014[\"domestic_supply_quantity\"] != 0  \n",
    "q5a_2014.loc[maskq5a,'ratio'] = q5a_2014.loc[maskq5a, 'other_uses']/q5a_2014.loc[maskq5a, 'domestic_supply_quantity']\n",
    "q5a_2014.ratio = q5a_2014.ratio.fillna(0)\n",
    "q5a_2014 = q5a_2014.sort_values(by=['ratio'], ascending = False).head(3)\n",
    "\n",
    "# Ditto for 2017\n",
    "q5a_2017 = data2[data2.year==2017]\n",
    "q5a_2017 = q5a_2017[q5a_2017.item.isin(most_exported_items_2017)].groupby(['country', 'item', 'year'], as_index = False)[['other_uses', 'domestic_supply_quantity']].sum()\n",
    "maskq5a = q5a_2017[\"domestic_supply_quantity\"] != 0  \n",
    "q5a_2017.loc[maskq5a,'ratio'] = q5a_2017.loc[maskq5a, 'other_uses']/q5a_2017.loc[maskq5a, 'domestic_supply_quantity']\n",
    "q5a_2017.ratio = q5a_2017.ratio.fillna(0)\n",
    "q5a_2017 = q5a_2017.sort_values(by=['ratio'], ascending = False).head(3)\n",
    "\n",
    "# Concatenating the two dataframes \n",
    "q5a = pd.concat([q5a_2014, q5a_2017]).reset_index(drop=True)\n",
    "\n",
    "q5a "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Have the greatest _feed_ to _(food+feed)_ ratio and what are they used for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe that only includes the 25 most exported items in 2014, \n",
    "# while keeping only the 'country', 'item', 'year','other_uses', 'domestic_supply_quantity' columns\n",
    "q5b_2014 = data2[data2.year==2014]\n",
    "q5b_2014 = q5b_2014[q5b_2014.item.isin(most_exported_items_2014)].groupby(['country', 'item', 'year'], as_index = False)[['food', 'feed']].sum()\n",
    "\n",
    "# Creating our 'other_uses' to 'domestic_supply_quantity' ratio column\n",
    "maskq5b = (q5b_2014['food'] + q5b_2014['feed']) != 0  \n",
    "q5b_2014.loc[maskq5b,'ratio'] = q5b_2014.loc[maskq5b, 'feed']/(q5b_2014.loc[maskq5b, 'feed'] + q5b_2014.loc[maskq5b, 'food'])\n",
    "q5b_2014.ratio = q5b_2014.ratio.fillna(0)\n",
    "q5b_2014 = q5b_2014.sort_values(by=['ratio'], ascending = False).head(3)\n",
    "\n",
    "# Ditto for 2017\n",
    "q5b_2017 = data2[data2.year==2017]\n",
    "q5b_2017 = q5b_2017[q5b_2017.item.isin(most_exported_items_2017)].groupby(['country', 'item', 'year'], as_index = False)[['food', 'feed']].sum()\n",
    "maskq5b = (q5b_2017['food'] + q5b_2017['feed']) != 0  \n",
    "q5b_2017.loc[maskq5b,'ratio'] = q5b_2017.loc[maskq5b, 'feed']/(q5b_2017.loc[maskq5b, 'feed']+q5b_2017.loc[maskq5b, 'food'])\n",
    "q5b_2017.ratio = q5b_2017.ratio.fillna(0)\n",
    "q5b_2017 = q5b_2017.sort_values(by=['ratio'], ascending = False).head(3)\n",
    "\n",
    "# Concatenating the two dataframes \n",
    "q5b = pd.concat([q5b_2014, q5b_2017]).reset_index(drop=True)\n",
    "\n",
    "q5b "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Taking only grains (cereals) for food and feed into account, what proportion (in terms of weight) is used for feed?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating our list of cereal items\n",
    "cereals_data = pd.read_csv(\"data/cereals.csv\")\n",
    "cereals = cereals_data['Item'].unique()\n",
    "cereals\n",
    "\n",
    "# Creating our dataframe that only includes the cereals items; \n",
    "# Grouped by year and item\n",
    "# Kept and summed the food and feed columns\n",
    "q6 = data2[data2['item'].isin(cereals)].groupby(['year'], as_index = False)[['food', 'feed']].sum()\n",
    "\n",
    "# Creating a mask to ensure no Inf values appear (due to division by 0)\n",
    "mask6 = (q6[\"food\"]+ q6[\"feed\"]) != 0 \n",
    "\n",
    "# Creating our final results (i.e. proportion column)\n",
    "q6.loc[mask6,'percentage'] = round(100*q6.loc[mask6, 'feed']/(q6.loc[mask6, 'food'] + q6.loc[mask6, 'feed']))\n",
    "q6[['year', 'percentage']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. How many tons of grains (cereals) could be released if the US reduced its production of animal products by 10%? Convert this quantity to kcal, and the number of potentially fed humans.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a dataframe containing only the cereals entries for the 'United States of America' for 2014\n",
    "q7 = data2[data2.item.isin(cereals)]\n",
    "q7 = q7[q7.country=='United States of America']\n",
    "q7 = q7[q7.year == 2014]\n",
    "\n",
    "# 10% of (cereals) feed in kg\n",
    "q7a = q7.feed.sum()*1000*0.1 \n",
    "\n",
    "# 10% of (cereals) feed in kcal\n",
    "q7b = round((q7.feed*1000*0.1  * q7.ratio_kcalkg).sum(), 0)\n",
    "\n",
    "# no. of potentially fed humans with the 10% cereals feed\n",
    "q7c = round(q7b/daily_calorie_req, 0)\n",
    "\n",
    "q7d = pd.DataFrame(np.array([[q7a, q7b, q7c]]), columns=['10%_feed_kg', '10%_feed_kcal', 'potential_humans_fed'])\n",
    "q7d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe containing only the cereals entries for the 'United States of America' for 2017\n",
    "q71 = data2[data2.item.isin(cereals)]\n",
    "q71 = q71[q71.country=='United States of America']\n",
    "q71 = q71[q71.year == 2017]\n",
    "\n",
    "# 10% of (cereals) feed in kg\n",
    "q71a = q71.feed.sum()*1000*0.1 \n",
    "\n",
    "# 10% of (cereals) feed in kcal\n",
    "q71b = round((q71.feed*1000*0.1  * q71.ratio_kcalkg).sum(), 0)\n",
    "\n",
    "# no. of potentially fed humans with the 10% cereals feed\n",
    "q71c = round(q71b/daily_calorie_req, 0)\n",
    "\n",
    "q71d = pd.DataFrame(np.array([[q71a, q71b, q71c]]), columns=['10%_feed_kg', '10%_feed_kcal', 'potential_humans_fed'])\n",
    "q71d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. In Thailand, what proportion of cassava is exported? What is the proportion of undernutrition?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q8 = data2[data2.country == 'Thailand']\n",
    "q8 = q8[q8.item == 'Cassava and products']\n",
    "#q8a = q8.item.unique()\n",
    "q8 = q8[['year','country','item','domestic_supply_quantity', 'export_quantity', 'feed', 'food', 'import_quantity', 'losses', \n",
    "         'other_uses', 'processing', 'production', 'seed', 'stock_variation', 'u_percentage']]\n",
    "q8['proportion_exported_quantity'] = 100*(q8['feed'] + q8['food'] + q8['losses'] + q8['other_uses'])/q8['export_quantity']\n",
    "q8[['year','country','item','proportion_exported_quantity', 'u_percentage']].set_index('year')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
